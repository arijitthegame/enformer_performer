{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb_ShvB9E8yM"
   },
   "source": [
    "Copyright 2021 DeepMind Technologies Limited\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXQjDxgdwUmW"
   },
   "source": [
    "This colab showcases training of the Enformer model published in\n",
    "\n",
    "**\"Effective gene expression prediction from sequence by integrating long-range interactions\"**\n",
    "\n",
    "Žiga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R. Ledsam, Agnieszka Grabska-Barwinska, Kyle R. Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, David R. Kelley\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AVkKjy3bh_A"
   },
   "source": [
    "## Steps\n",
    "\n",
    "- Setup tf.data.Dataset by directly accessing the Basenji2 data on GCS: `gs://basenji_barnyard/data`\n",
    "- Train the model for a few steps, alternating training on human and mouse data batches\n",
    "- Evaluate the model on human and mouse genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM_PMOT-2Xhi"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqR7ol3rxrtM"
   },
   "source": [
    "**Start the colab kernel with GPU**: Runtime -> Change runtime type -> GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhjR7StI1tZn"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiDFm-a41tKW",
    "outputId": "8b889c6e-f113-4664-f2c9-91110808ad92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dm-sonnet in ./env/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.7/site-packages (4.61.2)\n",
      "Requirement already satisfied: tabulate>=0.7.5 in ./env/lib/python3.7/site-packages (from dm-sonnet) (0.8.9)\n",
      "Requirement already satisfied: numpy>=1.16.3 in ./env/lib/python3.7/site-packages (from dm-sonnet) (1.19.5)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in ./env/lib/python3.7/site-packages (from dm-sonnet) (0.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.7/site-packages (from dm-sonnet) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./env/lib/python3.7/site-packages (from dm-sonnet) (1.12.1)\n",
      "Requirement already satisfied: dm-tree>=0.1.1 in ./env/lib/python3.7/site-packages (from dm-sonnet) (0.1.6)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/arijit_sehanobish1/enformer_performer/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dm-sonnet tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CokqDsb-fxme"
   },
   "outputs": [],
   "source": [
    "# Get enformer source code\n",
    "!wget -q https://raw.githubusercontent.com/deepmind/deepmind-research/master/enformer/attention_module.py\n",
    "!wget -q https://raw.githubusercontent.com/deepmind/deepmind-research/master/enformer/enformer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmffZS_306eb"
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTGOLrbZxNHK",
    "outputId": "f58b5c21-0764-4003-c794-aa89e5d336cc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Make sure the GPU is enabled \n",
    "# assert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -> Change runtime type -> GPU'\n",
    "\n",
    "# # Easier debugging of OOM\n",
    "# %env TF_ENABLE_GPU_GARBAGE_COLLECTION=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S9ywsUmT05C1"
   },
   "outputs": [],
   "source": [
    "import sonnet as snt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/home/arijit_sehanobish1/enformer_performer/performer/tf_version')\n",
    "import fast_attention_sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YUIbu0Xu1BnA"
   },
   "outputs": [],
   "source": [
    "assert snt.__version__.startswith('2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PWzsyJddILcx",
    "outputId": "3f1cac0f-6bce-430e-b3c0-9848d43e654c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xOhdaXG95eOl",
    "outputId": "1e57ef49-254a-4050-89af-61bc0f8ea577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# GPU colab has T4 with 16 GiB of memory\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xx--Nco09fN"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BbXyDdoShFzX"
   },
   "outputs": [],
   "source": [
    "import enformer_performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = enformer_performer.Enformer(channels=1536 // 4,  # Use 4x fewer channels to train faster.\n",
    "                          num_heads=4,\n",
    "                          num_transformer_layers=4,\n",
    "                          pooling_type='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enformer(\n",
       "    channels=384,\n",
       "    num_transformer_layers=4,\n",
       "    num_heads=4,\n",
       "    pooling_type='max',\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MEb8OZli2Nbu"
   },
   "outputs": [],
   "source": [
    "# @title `get_targets(organism)`\n",
    "def get_targets(organism):\n",
    "    targets_txt = f'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_{organism}.txt'\n",
    "    return pd.read_csv(targets_txt, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2BuZ2gmUbpXZ"
   },
   "outputs": [],
   "source": [
    "# @title `get_dataset(organism, subset, num_threads=8)`\n",
    "import glob\n",
    "import json\n",
    "import functools\n",
    "\n",
    "\n",
    "def organism_path(organism):\n",
    "    return os.path.join('gs://basenji_barnyard/data', organism)\n",
    "\n",
    "\n",
    "def get_dataset(organism, subset, num_threads=8):\n",
    "    metadata = get_metadata(organism)\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files(organism, subset),\n",
    "                                    compression_type='ZLIB',\n",
    "                                    num_parallel_reads=num_threads)\n",
    "    dataset = dataset.map(functools.partial(deserialize, metadata=metadata),\n",
    "                        num_parallel_calls=num_threads)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_metadata(organism):\n",
    "  # Keys:\n",
    "  # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n",
    "  # pool_width, crop_bp, target_length\n",
    "    path = os.path.join(organism_path(organism), 'statistics.json')\n",
    "    with tf.io.gfile.GFile(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def tfrecord_files(organism, subset):\n",
    "  # Sort the values by int(*).\n",
    "  return sorted(tf.io.gfile.glob(os.path.join(\n",
    "      organism_path(organism), 'tfrecords', f'{subset}-*.tfr'\n",
    "  )), key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "\n",
    "def deserialize(serialized_example, metadata):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "      'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "      'target': tf.io.FixedLenFeature([], tf.string),\n",
    "  }\n",
    "    example = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "    sequence = tf.reshape(sequence, (metadata['seq_length'], 4))\n",
    "    sequence = tf.cast(sequence, tf.float32)\n",
    "\n",
    "    target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "    target = tf.reshape(target,\n",
    "                      (metadata['target_length'], metadata['num_targets']))\n",
    "    target = tf.cast(target, tf.float32)\n",
    "\n",
    "    return {'sequence': sequence,\n",
    "          'target': target}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzGRXfwV4tYH"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "M_vr1mbl3jbD",
    "outputId": "2de351ed-f43e-4469-a681-2a437d97c946"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genome</th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>clip</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF833POA</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:cerebellum male adult (27 years) and mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF110QGM</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:frontal cortex male adult (27 years) and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF880MKD</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:chorion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF463ZLQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:Ishikawa treated with 0.02% dimethyl sul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF890OGQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:GM03348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  genome   identifier  \\\n",
       "0      0       0  ENCFF833POA   \n",
       "1      1       0  ENCFF110QGM   \n",
       "2      2       0  ENCFF880MKD   \n",
       "3      3       0  ENCFF463ZLQ   \n",
       "4      4       0  ENCFF890OGQ   \n",
       "\n",
       "                                                file  clip  scale sum_stat  \\\n",
       "0  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "1  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "2  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "3  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "4  /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "\n",
       "                                         description  \n",
       "0  DNASE:cerebellum male adult (27 years) and mal...  \n",
       "1  DNASE:frontal cortex male adult (27 years) and...  \n",
       "2                                      DNASE:chorion  \n",
       "3  DNASE:Ishikawa treated with 0.02% dimethyl sul...  \n",
       "4                                      DNASE:GM03348  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets_human = get_targets('human')\n",
    "df_targets_human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5313"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_targets_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_mouse = get_targets('mouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_targets_mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YDSKttXI4hMT"
   },
   "outputs": [],
   "source": [
    "human_dataset = get_dataset('human', 'train').batch(1).repeat()\n",
    "mouse_dataset = get_dataset('mouse', 'train').batch(1).repeat()\n",
    "human_mouse_dataset = tf.data.Dataset.zip((human_dataset, mouse_dataset)).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data_all = get_dataset('human', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: {sequence: (131072, 4), target: (896, 5313)}, types: {sequence: tf.float32, target: tf.float32}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: {sequence: (None, 131072, 4), target: (None, 896, 5313)}, types: {sequence: tf.float32, target: tf.float32}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2vx3116C7oFW"
   },
   "outputs": [],
   "source": [
    "it = iter(mouse_dataset)\n",
    "example = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XeztqJZ74ixT",
    "outputId": "39dc4051-5a19-4443-b6b0-bf6869faf5ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n",
      "{'sequence': (TensorShape([1, 131072, 4]), tf.float32), 'target': (TensorShape([1, 896, 5313]), tf.float32)}\n",
      "mouse\n",
      "{'sequence': (TensorShape([1, 131072, 4]), tf.float32), 'target': (TensorShape([1, 896, 1643]), tf.float32)}\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "it = iter(human_mouse_dataset)\n",
    "example = next(it)\n",
    "for i in range(len(example)):\n",
    "  print(['human', 'mouse'][i])\n",
    "  print({k: (v.shape, v.dtype) for k,v in example[i].items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHHNHzFVbvTk"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0U3hLJaUdZkG"
   },
   "outputs": [],
   "source": [
    "def create_step_function(model, optimizer):\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(batch, head, optimizer_clip_norm_global=0.2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(batch['sequence'], is_training=True)[head]\n",
    "        loss = tf.reduce_mean(\n",
    "          tf.keras.losses.poisson(batch['target'], outputs))\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "\n",
    "    return loss\n",
    "  return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZXv5HU_242Ut"
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.Variable(0., trainable=False, name='learning_rate')\n",
    "optimizer = snt.optimizers.Adam(learning_rate=learning_rate)\n",
    "num_warmup_steps = 5000\n",
    "target_learning_rate = 0.0005\n",
    "\n",
    "# model = enformer_performer.Enformer(channels=1536 // 4,  # Use 4x fewer channels to train faster.\n",
    "#                           num_heads=4,\n",
    "#                           num_transformer_layers=4,\n",
    "#                           pooling_type='max')\n",
    "\n",
    "train_step = create_step_function(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrbDaOMWcFUl",
    "outputId": "6a42f69c-3003-47f2-a8d2-1b94c52eb57e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 222509.50it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-13-c3553c570c78>:6 train_step  *\n        outputs = model(batch['sequence'], is_training=True)[head]\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:150 __call__  *\n        trunk_embedding = self.trunk(inputs, is_training=is_training)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:268 __call__  *\n        return inputs + self._module(inputs, is_training, *args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n\n    TypeError: tf____call__() missing 1 required positional argument: 'training'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fd3eff639287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbatch_human\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mouse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss_human\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_human\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mloss_mouse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mouse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mouse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-13-c3553c570c78>:6 train_step  *\n        outputs = model(batch['sequence'], is_training=True)[head]\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:150 __call__  *\n        trunk_embedding = self.trunk(inputs, is_training=is_training)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:268 __call__  *\n        return inputs + self._module(inputs, is_training, *args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n    /home/arijit_sehanobish1/enformer_performer/enformer_performer.py:201 __call__  *\n        outputs = mod(outputs, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/utils.py:151 _decorate_unbound_method  *\n        return decorator_fn(bound_method, self, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/sonnet/src/base.py:272 wrap_with_name_scope  *\n        return method(*args, **kwargs)\n\n    TypeError: tf____call__() missing 1 required positional argument: 'training'\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "steps_per_epoch = 20\n",
    "num_epochs = 5\n",
    "\n",
    "data_it = iter(human_mouse_dataset)\n",
    "global_step = 0\n",
    "for epoch_i in range(num_epochs):\n",
    "    for i in tqdm(range(steps_per_epoch)):\n",
    "        global_step += 1\n",
    "\n",
    "    if global_step > 1:\n",
    "        learning_rate_frac = tf.math.minimum(\n",
    "          1.0, global_step / tf.math.maximum(1.0, num_warmup_steps))      \n",
    "        learning_rate.assign(target_learning_rate * learning_rate_frac)\n",
    "\n",
    "    batch_human, batch_mouse = next(data_it)\n",
    "\n",
    "    loss_human = train_step(batch=batch_human, head='human')\n",
    "    loss_mouse = train_step(batch=batch_mouse, head='mouse')\n",
    "\n",
    "  # End of epoch.\n",
    "    print('')\n",
    "    print('loss_human', loss_human.numpy(),\n",
    "        'loss_mouse', loss_mouse.numpy(),\n",
    "        'learning_rate', optimizer.learning_rate.numpy()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs0f0z0RcCfz"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cellView": "form",
    "id": "8c4lNQrHkXSC"
   },
   "outputs": [],
   "source": [
    "# @title `PearsonR` and `R2` metrics\n",
    "\n",
    "def _reduced_shape(shape, axis):\n",
    "  if axis is None:\n",
    "    return tf.TensorShape([])\n",
    "  return tf.TensorShape([d for i, d in enumerate(shape) if i not in axis])\n",
    "\n",
    "\n",
    "class CorrelationStats(tf.keras.metrics.Metric):\n",
    "  \"\"\"Contains shared code for PearsonR and R2.\"\"\"\n",
    "\n",
    "  def __init__(self, reduce_axis=None, name='pearsonr'):\n",
    "    \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "    Args:\n",
    "      reduce_axis: Specifies over which axis to compute the correlation (say\n",
    "        (0, 1). If not specified, it will compute the correlation across the\n",
    "        whole tensor.\n",
    "      name: Metric name.\n",
    "    \"\"\"\n",
    "    super(CorrelationStats, self).__init__(name=name)\n",
    "    self._reduce_axis = reduce_axis\n",
    "    self._shape = None  # Specified in _initialize.\n",
    "\n",
    "  def _initialize(self, input_shape):\n",
    "    # Remaining dimensions after reducing over self._reduce_axis.\n",
    "    self._shape = _reduced_shape(input_shape, self._reduce_axis)\n",
    "\n",
    "    weight_kwargs = dict(shape=self._shape, initializer='zeros')\n",
    "    self._count = self.add_weight(name='count', **weight_kwargs)\n",
    "    self._product_sum = self.add_weight(name='product_sum', **weight_kwargs)\n",
    "    self._true_sum = self.add_weight(name='true_sum', **weight_kwargs)\n",
    "    self._true_squared_sum = self.add_weight(name='true_squared_sum',\n",
    "                                             **weight_kwargs)\n",
    "    self._pred_sum = self.add_weight(name='pred_sum', **weight_kwargs)\n",
    "    self._pred_squared_sum = self.add_weight(name='pred_squared_sum',\n",
    "                                             **weight_kwargs)\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    \"\"\"Update the metric state.\n",
    "\n",
    "    Args:\n",
    "      y_true: Multi-dimensional float tensor [batch, ...] containing the ground\n",
    "        truth values.\n",
    "      y_pred: float tensor with the same shape as y_true containing predicted\n",
    "        values.\n",
    "      sample_weight: 1D tensor aligned with y_true batch dimension specifying\n",
    "        the weight of individual observations.\n",
    "    \"\"\"\n",
    "    if self._shape is None:\n",
    "      # Explicit initialization check.\n",
    "      self._initialize(y_true.shape)\n",
    "    y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
    "    y_true = tf.cast(y_true, 'float32')\n",
    "    y_pred = tf.cast(y_pred, 'float32')\n",
    "\n",
    "    self._product_sum.assign_add(\n",
    "        tf.reduce_sum(y_true * y_pred, axis=self._reduce_axis))\n",
    "\n",
    "    self._true_sum.assign_add(\n",
    "        tf.reduce_sum(y_true, axis=self._reduce_axis))\n",
    "\n",
    "    self._true_squared_sum.assign_add(\n",
    "        tf.reduce_sum(tf.math.square(y_true), axis=self._reduce_axis))\n",
    "\n",
    "    self._pred_sum.assign_add(\n",
    "        tf.reduce_sum(y_pred, axis=self._reduce_axis))\n",
    "\n",
    "    self._pred_squared_sum.assign_add(\n",
    "        tf.reduce_sum(tf.math.square(y_pred), axis=self._reduce_axis))\n",
    "\n",
    "    self._count.assign_add(\n",
    "        tf.reduce_sum(tf.ones_like(y_true), axis=self._reduce_axis))\n",
    "\n",
    "  def result(self):\n",
    "    raise NotImplementedError('Must be implemented in subclasses.')\n",
    "\n",
    "  def reset_states(self):\n",
    "    if self._shape is not None:\n",
    "      tf.keras.backend.batch_set_value([(v, np.zeros(self._shape))\n",
    "                                        for v in self.variables])\n",
    "\n",
    "\n",
    "class PearsonR(CorrelationStats):\n",
    "  \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "  Computed as:\n",
    "  ((x - x_avg) * (y - y_avg) / sqrt(Var[x] * Var[y])\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, reduce_axis=(0,), name='pearsonr'):\n",
    "    \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "    Args:\n",
    "      reduce_axis: Specifies over which axis to compute the correlation.\n",
    "      name: Metric name.\n",
    "    \"\"\"\n",
    "    super(PearsonR, self).__init__(reduce_axis=reduce_axis,\n",
    "                                   name=name)\n",
    "\n",
    "  def result(self):\n",
    "    true_mean = self._true_sum / self._count\n",
    "    pred_mean = self._pred_sum / self._count\n",
    "\n",
    "    covariance = (self._product_sum\n",
    "                  - true_mean * self._pred_sum\n",
    "                  - pred_mean * self._true_sum\n",
    "                  + self._count * true_mean * pred_mean)\n",
    "\n",
    "    true_var = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
    "    pred_var = self._pred_squared_sum - self._count * tf.math.square(pred_mean)\n",
    "    tp_var = tf.math.sqrt(true_var) * tf.math.sqrt(pred_var)\n",
    "    correlation = covariance / tp_var\n",
    "\n",
    "    return correlation\n",
    "\n",
    "\n",
    "class R2(CorrelationStats):\n",
    "  \"\"\"R-squared  (fraction of explained variance).\"\"\"\n",
    "\n",
    "  def __init__(self, reduce_axis=None, name='R2'):\n",
    "    \"\"\"R-squared metric.\n",
    "\n",
    "    Args:\n",
    "      reduce_axis: Specifies over which axis to compute the correlation.\n",
    "      name: Metric name.\n",
    "    \"\"\"\n",
    "    super(R2, self).__init__(reduce_axis=reduce_axis,\n",
    "                             name=name)\n",
    "\n",
    "  def result(self):\n",
    "    true_mean = self._true_sum / self._count\n",
    "    total = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
    "    residuals = (self._pred_squared_sum - 2 * self._product_sum\n",
    "                 + self._true_squared_sum)\n",
    "\n",
    "    return tf.ones_like(residuals) - residuals / total\n",
    "\n",
    "\n",
    "class MetricDict:\n",
    "  def __init__(self, metrics):\n",
    "    self._metrics = metrics\n",
    "\n",
    "  def update_state(self, y_true, y_pred):\n",
    "    for k, metric in self._metrics.items():\n",
    "      metric.update_state(y_true, y_pred)\n",
    "\n",
    "  def result(self):\n",
    "    return {k: metric.result() for k, metric in self._metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "x80gX9LrhBU-"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, head, max_steps=None):\n",
    "  metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "  @tf.function\n",
    "  def predict(x):\n",
    "    return model(x, is_training=False)[head]\n",
    "\n",
    "  for i, batch in tqdm(enumerate(dataset)):\n",
    "    if max_steps is not None and i > max_steps:\n",
    "      break\n",
    "    metric.update_state(batch['target'], predict(batch['sequence']))\n",
    "\n",
    "  return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57fNitK9hzwd",
    "outputId": "947aaadb-dad2-4a00-ddac-d765f65d782f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:23,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'PearsonR': 0.0028573992}\n"
     ]
    }
   ],
   "source": [
    "metrics_human = evaluate_model(model,\n",
    "                               dataset=get_dataset('human', 'valid').batch(1).prefetch(2),\n",
    "                               head='human',\n",
    "                               max_steps=100)\n",
    "print('')\n",
    "print({k: v.numpy().mean() for k, v in metrics_human.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HY_wj95xiDtE",
    "outputId": "fea839f7-b6c9-46ed-aece-c56b02e9ea16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:21,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'PearsonR': 0.005183698}\n"
     ]
    }
   ],
   "source": [
    "metrics_mouse = evaluate_model(model,\n",
    "                               dataset=get_dataset('mouse', 'valid').batch(1).prefetch(2),\n",
    "                               head='mouse',\n",
    "                               max_steps=100)\n",
    "print('')\n",
    "print({k: v.numpy().mean() for k, v in metrics_mouse.items()})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "enformer-training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
